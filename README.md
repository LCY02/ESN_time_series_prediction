# Echo State Networks for Time Series Forecasting

This repository explores Echo State Networks (ESNs) for forecasting tasks using various training techniques. It demonstrates implementations, comparisons, and experiments on two standard benchmark time series datasets.

## 1. Standard Echo State Network (ESN)

This section presents a standard ESN implementation:

- **Network details**: No output feedback or leaky-integrator neurons.
- **Training method**: Regularized least squares (ridge regression).
- **Forecasting task**: Multi-step ahead predictions evaluated across different forecasting horizons (*k*).
- **Datasets**:
  - `2sine`: Synthetic data combining two sine waves.
  - `Lorenz`: Chaotic dataset generated by the Lorenz attractor.

Performance is analyzed by comparing forecast accuracy across various prediction horizons.

## 2. Online Gradient-Descent ESN

This part introduces an ESN trained using an online gradient-descent method:

- **Network details**: Weights updated sequentially after each data point.
- **Training method**: Incremental gradient descent.
- **Forecasting task**: Evaluated on the same multi-step forecasting tasks and datasets (`2sine`, `Lorenz`).
- **Hyperparameter tuning**: Detailed exploration and analysis of hyperparameters affecting performance.

Comparison with the standard ESN is provided, analyzing performance differences as the prediction horizon (*k*) increases.

## 3. FORCE Learning Algorithm

An advanced training implementation using the FORCE algorithm:

- **Algorithm**: FORCE learning as described by Sussillo and Abbott (2009).
- **Forecasting task**: Evaluated on `2sine` and `Lorenz` datasets, providing insights into performance compared to the standard and gradient-descent trained ESNs.

---

### Datasets
- `2sine`: Synthetic sinusoidal dataset.
- `Lorenz`: Dataset derived from the Lorenz chaotic system.